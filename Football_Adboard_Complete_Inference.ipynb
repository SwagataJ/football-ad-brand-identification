{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SwagataJ/football-ad-brand-identification/blob/main/Football_Adboard_Complete_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N8DShJpvb-8",
        "outputId": "192c6312-2d0e-4050-b29f-4a29542b91d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/drive/MyDrive/Football-Adboard/setup.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrQCtjqwyOtC",
        "outputId": "3f8aced3-404d-4255-c50c-1275790c670a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (6.0.1)\n",
            "Requirement already satisfied: wcmatch in /usr/local/lib/python3.10/dist-packages (8.4.1)\n",
            "Requirement already satisfied: bracex>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from wcmatch) (2.3.post1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (0.29.36)\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-28aivjjb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-28aivjjb\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 57bdb21249d5418c130d54e2ebdc94dda7a4c01a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.65.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.12.3)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.9)\n",
            "Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (1.3.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (23.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.6)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (0.11.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (3.9.1)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.56.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.4.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.41.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n",
            "fatal: destination path 'U-2-Net' already exists and is not an empty directory.\n",
            "fatal: destination path 'glass-text-spotting' already exists and is not an empty directory.\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from -r glass-text-spotting/requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r glass-text-spotting/requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.10/dist-packages (from -r glass-text-spotting/requirements.txt (line 3)) (0.1.9)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from -r glass-text-spotting/requirements.txt (line 4)) (1.3.0.post4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r glass-text-spotting/requirements.txt (line 5)) (1.2.2)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (from -r glass-text-spotting/requirements.txt (line 7)) (0.4.8)\n",
            "Requirement already satisfied: polygon3 in /usr/local/lib/python3.10/dist-packages (from -r glass-text-spotting/requirements.txt (line 8)) (3.0.9.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from -r glass-text-spotting/requirements.txt (line 9)) (5.13.1)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (from -r glass-text-spotting/requirements.txt (line 10)) (1.3.8)\n",
            "Requirement already satisfied: levenshtein in /usr/local/lib/python3.10/dist-packages (from -r glass-text-spotting/requirements.txt (line 11)) (0.21.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r glass-text-spotting/requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r glass-text-spotting/requirements.txt (line 2)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r glass-text-spotting/requirements.txt (line 2)) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r glass-text-spotting/requirements.txt (line 2)) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r glass-text-spotting/requirements.txt (line 2)) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r glass-text-spotting/requirements.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r glass-text-spotting/requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r glass-text-spotting/requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from iopath->-r glass-text-spotting/requirements.txt (line 3)) (4.65.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath->-r glass-text-spotting/requirements.txt (line 3)) (2.7.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r glass-text-spotting/requirements.txt (line 5)) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r glass-text-spotting/requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r glass-text-spotting/requirements.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->-r glass-text-spotting/requirements.txt (line 9)) (8.2.2)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio->-r glass-text-spotting/requirements.txt (line 10)) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio->-r glass-text-spotting/requirements.txt (line 10)) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio->-r glass-text-spotting/requirements.txt (line 10)) (2023.7.22)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio->-r glass-text-spotting/requirements.txt (line 10)) (8.1.6)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio->-r glass-text-spotting/requirements.txt (line 10)) (0.7.2)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio->-r glass-text-spotting/requirements.txt (line 10)) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio->-r glass-text-spotting/requirements.txt (line 10)) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio->-r glass-text-spotting/requirements.txt (line 10)) (67.7.2)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from levenshtein->-r glass-text-spotting/requirements.txt (line 11)) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r glass-text-spotting/requirements.txt (line 2)) (1.16.0)\n",
            "--2023-07-28 05:25:06--  https://glass-text-spotting.s3.eu-west-1.amazonaws.com/models/glass_250k_icdar15_fintune.pth\n",
            "Resolving glass-text-spotting.s3.eu-west-1.amazonaws.com (glass-text-spotting.s3.eu-west-1.amazonaws.com)... 52.92.34.154, 52.218.46.18, 52.218.25.248, ...\n",
            "Connecting to glass-text-spotting.s3.eu-west-1.amazonaws.com (glass-text-spotting.s3.eu-west-1.amazonaws.com)|52.92.34.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 610631276 (582M) [binary/octet-stream]\n",
            "Saving to: ‘glass-text-spotting/models/glass_icdar15.pth’\n",
            "\n",
            "glass-text-spotting 100%[===================>] 582.34M  27.7MB/s    in 22s     \n",
            "\n",
            "2023-07-28 05:25:29 (26.0 MB/s) - ‘glass-text-spotting/models/glass_icdar15.pth’ saved [610631276/610631276]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd U-2-Net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6qqNDg2zHXz",
        "outputId": "bf6a1cbc-fce1-4101-85f0-f8ed4ad1123b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/U-2-Net\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "assert torch.cuda.is_available(), \"Please choose a GPU enabled machine\""
      ],
      "metadata": {
        "id": "1KV81O_NzL8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model import U2NET\n",
        "\n",
        "model = torch.load(\"/content/drive/MyDrive/Football-Adboard/u2netsu2net_bce_itr_2938_train_0.091297_tar_0.008402.pth\")\n",
        "net = U2NET(3, 1)\n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "net.load_state_dict(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgTdvihHzWtw",
        "outputId": "cc2c8e0c-b4e6-4c8f-86f7-e1f4d3a40486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd glass-text-spotting/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc9Yt3LnzYDW",
        "outputId": "0f0fa78a-0e06-4520-895d-e57982392305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/U-2-Net/glass-text-spotting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import math\n",
        "import json\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import io\n",
        "from torchvision.transforms import functional as fn\n",
        "from torchvision.transforms import (\n",
        "    functional as fn, Compose,ToPILImage,ToTensor,Resize )\n",
        "\n",
        "from glass.evaluation.text_evaluator import get_instances_text\n",
        "from glass.inference.glass_runner import GlassRunner\n",
        "\n",
        "\n",
        "from wcmatch import glob, pathlib\n",
        "from statistics import mode\n",
        "from rapidfuzz.fuzz import token_set_ratio, partial_ratio\n",
        "from rapidfuzz.process import extractOne, extract\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "3aCnXk5czedB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"/content/drive/MyDrive/Football-Adboard/Test_video.mp4\"\n",
        "BATCH_SIZE = 1\n",
        "counter = 1"
      ],
      "metadata": {
        "id": "JNUB3IbnzlW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "databaseFile = open('/content/drive/MyDrive/Football-Adboard/brand_database.json')\n",
        "database = json.load(databaseFile)\n",
        "\n",
        "adBoardItems = database.keys()"
      ],
      "metadata": {
        "id": "Rlw4NvhUYo2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def variance_of_laplacian(image):\n",
        "    '''\n",
        "    function to calculate laplacian variance for blur detection\n",
        "\n",
        "    :param image:\n",
        "    :return: variance value\n",
        "    '''\n",
        "    return cv2.Laplacian(image, cv2.CV_64FC1).var()"
      ],
      "metadata": {
        "id": "uRCKzSQ4X_06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frame(video, fps, start, durationInSeconds, size):\n",
        "\n",
        "    print(durationInSeconds)\n",
        "    second = start\n",
        "    success = 1\n",
        "\n",
        "    best_frame = video.read()\n",
        "\n",
        "    image_batch = []\n",
        "    while second < durationInSeconds and success:\n",
        "        best_var = 0\n",
        "\n",
        "        for i in range(math.floor(fps)):\n",
        "            success, image = video.read()\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            curr_var = variance_of_laplacian(gray)\n",
        "\n",
        "            if curr_var > best_var:\n",
        "                best_var = curr_var\n",
        "                best_frame = image\n",
        "\n",
        "        image_batch.append(cv2.cvtColor(best_frame,cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        # if len(image_batch) == BATCH_SIZE:\n",
        "        #     image_batch = np.asarray(image_batch)\n",
        "        #     send_to_seg_model(image_batch,size)\n",
        "\n",
        "        #     image_batch = []\n",
        "\n",
        "        second += 1\n",
        "    send_to_seg_model(image_batch, size)"
      ],
      "metadata": {
        "id": "VTm_g2xwhXEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def send_to_seg_model(batch,size):\n",
        "    batch_segment = np.zeros_like(batch)\n",
        "    for c,i in enumerate(batch):\n",
        "      image_og = torch.from_numpy(i).permute(2,0,1).cuda()\n",
        "      image = fn.resize(image_og,[320,320]).unsqueeze(0).float().cuda()\n",
        "      d1,*_= net(image)\n",
        "      mask3 = fn.resize(d1[:,0,:,:] > 0.3,size)\n",
        "\n",
        "      segmented3d = torch.masked_fill(image_og,mask3==0,value=0)\n",
        "      #cv2_imshow(segmented3d)\n",
        "      #print(get_pred(ocr_prediction(segmented3d)))\n",
        "      #====\n",
        "      transform = ToPILImage()\n",
        "      image = transform(segmented3d[[2,1,0],:,:])\n",
        "      ocr_text, image_np = ocr_prediction(image)\n",
        "      brand_name = get_pred(ocr_text)\n",
        "      #====\n",
        "      #segmented3d = segmented3d.permute(1,2,0)[:,:,[2,1,0]].cpu().numpy()\n",
        "      #cv2_imshow(segmented3d)\n",
        "      # np.resize(image_np, (30, 1080, 1920//2, 3))\n",
        "      # print(image_np.size)\n",
        "      #image_np = image_np.resize()\n",
        "      # text = brand_name + \"\\n\" + \" \".join(ocr_text)\n",
        "      # brand_seg = cv2.putText(image_np, brand_name, (100,650),\n",
        "      #                              cv2.FONT_HERSHEY_SIMPLEX,2,(57,255,20),2,cv2.LINE_AA)\n",
        "      batch_segment[c] = cv2.putText(image_np, \" \".join(ocr_text), (100,700),\n",
        "                                    cv2.FONT_HERSHEY_SIMPLEX,1,(57,255,20),2,cv2.LINE_AA)\n",
        "\n",
        "    np.save(\"/content/Batch_segment_only_ocr\", batch_segment)\n",
        "    #create_mask_video(batch_segment)\n",
        "    #final_join_video()\n",
        "      # return batch_segment"
      ],
      "metadata": {
        "id": "owcqyG2whaRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ocr_prediction(img):\n",
        "    '''\n",
        "    This function performs the OCR predictions using Glass Text Spotting by Amazon Science\n",
        "\n",
        "    :param: img\n",
        "    :param: second\n",
        "    :return: nothing\n",
        "    '''\n",
        "\n",
        "    image = np.asarray(img.convert('RGB'))\n",
        "    # cv2_imshow(image)\n",
        "    rgb_image = image\n",
        "    try:\n",
        "      preds = glass_runner(image)\n",
        "      text, text_scores, _ = get_instances_text(text_probs=preds.pred_text_prob, text_encoder=glass_runner.text_encoder, onlyRemoveFirstLastCharacter=False)\n",
        "      return text, rgb_image\n",
        "      # print(\"OCR Text:\", text)\n",
        "      # print(\"Fuzzy Text:\", get_pred(text))\n",
        "    except AttributeError:\n",
        "      # print([])\n",
        "      return [], rgb_image"
      ],
      "metadata": {
        "id": "j1DVSI9Phdi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_closest_match(text):\n",
        "    string = extractOne(text, adBoardItems, scorer=partial_ratio,score_cutoff=92)\n",
        "    if string is not None:\n",
        "        return string[0]\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_brand(text):\n",
        "    match = get_closest_match(text)\n",
        "    if match is not None:\n",
        "        return database[match]\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_matches(text):\n",
        "    return extract(text, adBoardItems)\n",
        "\n",
        "def get_pred(lst):\n",
        "  temp = []\n",
        "  if len(lst):\n",
        "    for item in lst:\n",
        "      brand = get_brand(item.lower())\n",
        "      if brand is not None and len(item)>2:\n",
        "        temp.append(brand)\n",
        "\n",
        "  return mode(temp) if len(temp) else \" \""
      ],
      "metadata": {
        "id": "tXXaYIeehjyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mask_video(segment_batch):\n",
        "  batch_seg_fps = np.repeat(segment_batch,30,axis=0)\n",
        "  print(batch_seg_fps.shape)\n",
        "\n",
        "  video = cv2.VideoWriter('/content/mask_video_fps.mp4',cv2.VideoWriter_fourcc(*'mp4v'), 30, (1920,1080))\n",
        "\n",
        "  for i in batch_seg_fps:\n",
        "    video.write(i)\n",
        "  video.release()"
      ],
      "metadata": {
        "id": "hGRUQm6J8C7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final_join_video():\n",
        "  cap1 = cv2.VideoCapture(video_path)\n",
        "  cap2 = cv2.VideoCapture(\"/content/mask_video_fps.mp4\")\n",
        "\n",
        "  BG = np.zeros((1080, 1920*2, 3), dtype = np.uint8)\n",
        "\n",
        "  def Fram_connect(frame1, frame2, H, W, BG):\n",
        "    BG[0:H,0:W] = frame1\n",
        "    BG[0:H,W:W*2] = frame2\n",
        "    return cv2.resize(BG,(W,H),interpolation = cv2.INTER_AREA)\n",
        "\n",
        "\n",
        "  fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
        "  videowriter = cv2.VideoWriter(\"/content/output_video\" + \".avi\",fourcc,30,(1920,1080))\n",
        "\n",
        "  while (True):\n",
        "    _, frame1=cap1.read()\n",
        "    _, frame2=cap2.read()\n",
        "    videowriter.write(Fram_connect(frame1, frame2, 1080, 1920,BG))"
      ],
      "metadata": {
        "id": "P0RAjf648M_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glass_model_path = './models/glass_icdar15.pth'\n",
        "config_path = './configs/glass_finetune_icdar15.yaml'\n",
        "glass_runner = GlassRunner(model_path=glass_model_path, config_path=config_path, post_process=False)"
      ],
      "metadata": {
        "id": "B97WTrW-1Rux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# import extract_frame\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "videoStartAt = 0\n",
        "\n",
        "video = cv2.VideoCapture(video_path)\n",
        "video.set(1,videoStartAt)\n",
        "\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "totalNoFrames = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "videoDurationInSeconds = totalNoFrames // fps\n",
        "\n",
        "## for testing, performing inference for 14 seconds of video\n",
        "videoLength = 600\n",
        "extract_frame(video, fps, videoStartAt+videoLength)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Time taken for inference of {} seconds of video  is {}s\".format(videoLength, end_time - start_time))"
      ],
      "metadata": {
        "id": "AAvnNimw18lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference 23 second se chalu karenge, for video\n",
        "do it for 2 mins, i.e., 120 secs"
      ],
      "metadata": {
        "id": "cu8K76R3mERU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# import extract_frame\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "videoStartAt = 0\n",
        "\n",
        "video = cv2.VideoCapture(video_path)\n",
        "video.set(1,videoStartAt)\n",
        "\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "totalNoFrames = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "videoDurationInSeconds = totalNoFrames // fps\n",
        "\n",
        "## for testing, performing inference for 14 seconds of video\n",
        "videoLength = 120\n",
        "extract_frame(video, fps, videoStartAt+videoLength)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Time taken for inference of {} seconds of video  is {}s\".format(videoLength, end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THZbtRVZnBfF",
        "outputId": "b83d67f1-1655-4da8-c27b-b112afc524b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for inference of 120 seconds of video  is 138.24648141860962s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# import extract_frame\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "videoStartAt = 0\n",
        "\n",
        "video = cv2.VideoCapture(video_path)\n",
        "video.set(1,videoStartAt)\n",
        "\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "totalNoFrames = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "videoDurationInSeconds = totalNoFrames // fps\n",
        "\n",
        "## for testing, performing inference for 14 seconds of video\n",
        "videoLength = 240\n",
        "extract_frame(video, fps, videoStartAt+videoLength)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Time taken for inference of {} seconds of video  is {}s\".format(videoLength, end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHb95jKYor2u",
        "outputId": "aa28b074-c6ca-42f7-b752-212821a3b592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for inference of 240 seconds of video  is 294.39005398750305s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# import extract_frame\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "videoStartAt = 0\n",
        "\n",
        "video = cv2.VideoCapture(video_path)\n",
        "video.set(1,videoStartAt)\n",
        "\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "totalNoFrames = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "videoDurationInSeconds = totalNoFrames // fps\n",
        "\n",
        "## for testing, performing inference for 14 seconds of video\n",
        "videoLength = 480\n",
        "extract_frame(video, fps, videoStartAt+videoLength)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Time taken for inference of {} seconds of video  is {}s\".format(videoLength, end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ1SWKuJpdG8",
        "outputId": "3b2af639-b0a0-48ad-93b5-7af5d1b8cce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for inference of 480 seconds of video  is 543.8926026821136s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# import extract_frame\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "videoStartAt = 0\n",
        "\n",
        "video = cv2.VideoCapture(video_path)\n",
        "video.set(1,videoStartAt)\n",
        "\n",
        "fps = video.get(cv2.CAP_PROP_FPS)\n",
        "totalNoFrames = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "videoDurationInSeconds = totalNoFrames // fps\n",
        "\n",
        "## for testing, performing inference for 14 seconds of video\n",
        "videoLength = 600\n",
        "extract_frame(video, fps, videoStartAt+videoLength)\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Time taken for inference of {} seconds of video  is {}s\".format(videoLength, end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZrnd8a0pgrg",
        "outputId": "86253703-bbeb-47df-d0e5-b94ea2ba145b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for inference of 600 seconds of video  is 678.9105579853058s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import time\n",
        "\n",
        "#start_time = time.time()\n",
        "\n",
        "videoStartAt = 24\n",
        "\n",
        "video = cv2.VideoCapture(video_path)\n",
        "#print(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
        "# video.set(videoStartAt*, videoStartAt)\n",
        "#print(video.get(cv2.CAP_PROP_POS_FRAMES))\n",
        "\n",
        "\n",
        "fps    = video.get(cv2.CAP_PROP_FPS)\n",
        "width  = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "totalNoFrames = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "videoDurationInSeconds = totalNoFrames // fps\n",
        "videoLength = 120\n",
        "video.set(1, videoStartAt*int(fps))\n",
        "\n",
        "extract_frame(video, fps, videoStartAt, videoStartAt+videoLength, [height,width])\n",
        "#end_time = time.time()\n",
        "\n",
        "#print(\"Time taken for inference of {} minute of video  is {}s\".format(videoDurationInSeconds/60, end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB4uhzWq_ju-",
        "outputId": "7811e122-696f-4ecb-f3e5-39b780a6a39f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "144\n"
          ]
        }
      ]
    }
  ]
}